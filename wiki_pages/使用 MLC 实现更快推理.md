# åœ¨ Jetson ä¸Šä½¿ç”¨ MLC LLM é‡åŒ– Llama2-7B

## ä»‹ç»

è¿‘å¹´æ¥ï¼ŒGPT-3 ç­‰å¤§å‹è¯­è¨€æ¨¡å‹å½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¤§å¤šåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œéœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œä¸é€‚åˆåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶äººå‘˜å¼€å‘äº†é‡åŒ–æŠ€æœ¯ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹å°†å¤§å‹æ¨¡å‹å‹ç¼©ä¸ºæ›´å°çš„æ¨¡å‹ã€‚

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† [Llama2-7B](https://huggingface.co/meta-llama/Llama-2-7b-hf) çš„é‡åŒ–ç‰ˆæœ¬ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ 1.5TB æ•°æ®ä¸Šè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°†å…¶éƒ¨ç½²åœ¨ Jetson Orin ä¸Šã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨ [æœºå™¨å­¦ä¹ ç¼–è¯‘å™¨å¤§è¯­è¨€æ¨¡å‹](https://llm.mlc.ai)(MLC LLM) æ¥åŠ é€Ÿæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚é€šè¿‡åœ¨ [Jetson Orin NX](https://www.seeedstudio.com/reComputer-J4012-p-5586.html) ä¸Šéƒ¨ç½²é‡åŒ–çš„ Llama2-7B å’Œ MLC LLMï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºå¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ç¨‹åºï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæä¾›é«˜ç²¾åº¦å’Œä½å»¶è¿Ÿã€‚

![](https://files.seeedstudio.com/wiki/reComputer-Jetson/A608/MLC_LLM.gif)

## ç¡¬ä»¶ç»„ä»¶

|  |  |  |
| --- | --- | --- |
| reComputerï¼ˆæˆ–å…¶ä»–åŸºäº Jetson çš„è®¾å¤‡ï¼‰|  |  | | --- | --- | | | [**ç«‹å³è·å– ğŸ–±ï¸**](https://www.seeedstudio.com/reComputer-J4012-p-5586.html) | | |

## å®‰è£…ä¾èµ–

```
sudo apt-get update && sudo apt-get install git python3-pip
```

```
git clone --depth=1 https://github.com/dusty-nv/jetson-containers
```

```
cd jetson-containers pip3 install -r requirements.txt
```

```
cd ./data && git clone https://github.com/LJ-Hao/MLC-LLM-on-Jetson-Nano.git && cd ..
```

## å®‰è£…å¹¶è¿è¡Œå®¹å™¨

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…é•œåƒ

```
./run.sh --env HUGGINGFACE_TOKEN=<YOUR-ACCESS-TOKEN> $(./autotag mlc) /bin/bash -c 'ln -s $(huggingface-downloader meta-llama/Llama-2-7b-chat-hf) /data/models/mlc/dist/models/Llama-2-7b-chat-hf'
```

ä½¿ç”¨ `sudo docker images` æ£€æŸ¥é•œåƒæ˜¯å¦å·²å®‰è£…

![pir](https://files.seeedstudio.com/wiki/reComputer-Jetson/A608/docker_image.png)

### ç¬¬äºŒæ­¥ï¼šå®‰è£… Llama2-7b-chat-hf å¹¶ä½¿ç”¨ MLC é‡åŒ–æ¨¡å‹

```
./run.sh $(./autotag mlc) \  
python3 -m mlc_llm.build \  
--model Llama-2-7b-chat-hf \  
--quantization q4f16_ft \  
--artifact-path /data/models/mlc/dist \  
--max-seq-len 4096 \  
--target cuda \  
--use-cuda-graph \  
--use-flash-attn-mqa
```

### ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œå¹¶è¿›å…¥ docker

```
./run.sh <YOUR IMAGE NAME>   
#å¯¹æˆ‘æ¥è¯´æ˜¯ dustynv/mlc:51fb0f4-builder-r35.4.1ï¼Œè¯·æ£€æŸ¥ç¬¬ä¸€æ­¥çš„ç»“æœ
```

![pir](https://files.seeedstudio.com/wiki/reComputer-Jetson/A608/docker_run.png)

## è®©æˆ‘ä»¬è¿è¡Œå®ƒ

### è¿è¡Œæœªç» MLC LLM é‡åŒ–çš„ Llama

```
cd /data/MLC-LLM-on-Jetson && python3 Llama-2-7b-chat-hf.py
```

![pir](https://files.seeedstudio.com/wiki/reComputer-Jetson/A608/Llama-2-7b-chat-hf.png)

ä½ å¯ä»¥çœ‹åˆ°ï¼Œåœ¨æ²¡æœ‰ä½¿ç”¨ MLC é‡åŒ–çš„æƒ…å†µä¸‹ï¼ŒJetson Nano 16GB å¯ä»¥åŠ è½½æ¨¡å‹ä½†æ— æ³•è¿è¡Œã€‚

### è¿è¡Œç»è¿‡ MLC LLM é‡åŒ–çš„ Llama

```
cd /data/MLC-LLM-on-Jetson && python3 Llama-2-7b-chat-hf-q4f16_ft.py
```

ç»“æœå¦‚ä¸‹ï¼š

![pir](https://files.seeedstudio.com/wiki/reComputer-Jetson/A608/Llama-2-7b-chat-hf-q4f16_ft.png)

## åœ¨ Jetson Orin NX 16GB ä¸Šä½¿ç”¨ MLC è¿è¡Œ Llama çš„è§†é¢‘

## é¡¹ç›®å±•æœ›

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•åœ¨ Jetson Orin ä¸Šéƒ¨ç½²é‡åŒ–ç‰ˆæœ¬çš„ Llama2-7B å’Œ MLC LLMã€‚å‡­å€Ÿ Jetson Orin å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæä¾›é«˜ç²¾åº¦å’Œä½å»¶è¿Ÿçš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ç¨‹åºã€‚æœªæ¥ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¢ç´¢åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹çš„æ½œåŠ›ï¼Œå¹¶å¼€å‘æ›´é«˜æ•ˆå’Œä¼˜åŒ–çš„éƒ¨ç½²æ–¹æ³•ã€‚